{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lf5lYawIw8tE"
   },
   "source": [
    "# **Waste Material Segregation for Improving Waste Management**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY1InIbkw80B"
   },
   "source": [
    "## **Objective**\n",
    "\n",
    "The objective of this project is to implement an effective waste material segregation system using convolutional neural networks (CNNs) that categorises waste into distinct groups. This process enhances recycling efficiency, minimises environmental pollution, and promotes sustainable waste management practices.\n",
    "\n",
    "The key goals are:\n",
    "\n",
    "* Accurately classify waste materials into categories like cardboard, glass, paper, and plastic.\n",
    "* Improve waste segregation efficiency to support recycling and reduce landfill waste.\n",
    "* Understand the properties of different waste materials to optimise sorting methods for sustainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZGTCfyUxalZ"
   },
   "source": [
    "## **Data Understanding**\n",
    "\n",
    "The Dataset consists of images of some common waste materials.\n",
    "\n",
    "1. Food Waste\n",
    "2. Metal\n",
    "3. Paper\n",
    "4. Plastic\n",
    "5. Other\n",
    "6. Cardboard\n",
    "7. Glass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZJtmMnzQjAr"
   },
   "source": [
    "**Data Description**\n",
    "\n",
    "* The dataset consists of multiple folders, each representing a specific class, such as `Cardboard`, `Food_Waste`, and `Metal`.\n",
    "* Within each folder, there are images of objects that belong to that category.\n",
    "* However, these items are not further subcategorised. <br> For instance, the `Food_Waste` folder may contain images of items like coffee grounds, teabags, and fruit peels, without explicitly stating that they are actually coffee grounds or teabags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBFt43WDzWSJ"
   },
   "source": [
    "## **1. Load the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dfy0rjJ1yzFl"
   },
   "source": [
    "Load and unzip the dataset zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N35LLuWXzUQH"
   },
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DmZo7m1-J_Ou"
   },
   "outputs": [],
   "source": [
    "# Recommended versions:\n",
    "\n",
    "# numpy version: 1.26.4\n",
    "# pandas version: 2.2.2\n",
    "# seaborn version: 0.13.2\n",
    "# matplotlib version: 3.10.0\n",
    "# PIL version: 11.1.0\n",
    "# tensorflow version: 2.18.0\n",
    "# keras version: 3.8.0\n",
    "# sklearn version: 1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dzM50pygphUe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "!pip install tensorflow\n",
    "import numpy as mp \n",
    "import pandas as pd \n",
    "import os\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNAzJi1c9WAX"
   },
   "source": [
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TM1qn2DKtjR6"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/dataset.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m extact_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/data/dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# unzipping the file\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(zip_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[0;32m     10\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(extact_path)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# verify the directory structure\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\zipfile\\__init__.py:1331\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(file, filemode)\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/dataset.zip'"
     ]
    }
   ],
   "source": [
    "# Load and unzip the dataset\n",
    "\n",
    "import zipfile \n",
    "# path to the uploaded zip file\n",
    "zip_path = '/mnt/data/dataset.zip'\n",
    "extact_path = '/mnt/data/dataset'\n",
    "\n",
    "# unzipping the file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extact_path)\n",
    "\n",
    "# verify the directory structure\n",
    "print(\"contents:\")  \n",
    "print(os.listdir(extact_path))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDp_EWxVOhUu"
   },
   "source": [
    "## **2. Data Preparation** <font color=red> [25 marks] </font><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7Ac8VxvjWnw"
   },
   "source": [
    "### **2.1 Load and Preprocess Images** <font color=red> [8 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghmtINrMXDMy"
   },
   "source": [
    "Let us create a function to load the images first. We can then directly use this function while loading images of the different categories to load and crop them in a single step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZQ1UZNfQCWX"
   },
   "source": [
    "#### **2.1.1** <font color=red> [3 marks] </font><br>\n",
    "Create a function to load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "y6klNk9rcAtr"
   },
   "outputs": [],
   "source": [
    "# Create a function to load the raw images\n",
    "\n",
    "def load_images_from_directory(base_path, target_size=(128, 128), class_names=None):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # If class_names are not specified, infer from directory structure\n",
    "    if class_names is None:\n",
    "        class_names = sorted(os.listdir(base_path))\n",
    "    \n",
    "    class_to_index = {cls_name: idx for idx, cls_name in enumerate(class_names)}\n",
    "    \n",
    "    for cls in class_names:\n",
    "        class_dir = os.path.join(base_path, cls)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "            \n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                img = cv2.resize(img, target_size)\n",
    "                images.append(img)\n",
    "                labels.append(class_to_index[cls])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels, class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J01VQrLhQsxx"
   },
   "source": [
    "#### **2.1.2** <font color=red> [5 marks] </font><br>\n",
    "Load images and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_C9Oo0PTtYLf"
   },
   "source": [
    "Load the images from the dataset directory. Labels of images are present in the subdirectories.\n",
    "\n",
    "Verify if the images and labels are loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zm2zlZbmamzy"
   },
   "outputs": [],
   "source": [
    "# Get the images and their labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26Is-EwKuyGf"
   },
   "source": [
    "Perform any operations, if needed, on the images and labels to get them into the desired format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I64rs77bkAYk"
   },
   "source": [
    "### **2.2 Data Visualisation** <font color=red> [9 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCAepbyAQdI2"
   },
   "source": [
    "#### **2.2.1** <font color=red> [3 marks] </font><br>\n",
    "Create a bar plot to display the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gm5LuWSFqTac"
   },
   "outputs": [],
   "source": [
    "# Visualise Data Distribution\n",
    "\n",
    "# count number of samples per class\n",
    "label_counts = pd.Series(labels).value_counts().sort_index()\n",
    "label_names = [class_names[i] for i in label_counts.index]\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(label_names, label_counts, color='skyblue')\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('Number of Images ')\n",
    "plt.title('Image count per class')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNWsPfTzRh7x"
   },
   "source": [
    "#### **2.2.2** <font color=red> [3 marks] </font><br>\n",
    "Visualise some sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37yXZzfLyOWt"
   },
   "outputs": [],
   "source": [
    "# Visualise Sample Images (across different labels)\n",
    "def show_sample_images(images, labels, class_names, samples_per_class=3):\n",
    "    plt.figure(figsize=(15, len(class_names) * 2))\n",
    "    \n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        # Get all indices for this class\n",
    "        class_indices = [i for i, label in enumerate(labels) if label == class_index]\n",
    "        selected_indices = random.sample(class_indices, min(samples_per_class, len(class_indices)))\n",
    "        \n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            plt_idx = class_index * samples_per_class + i + 1\n",
    "            plt.subplot(len(class_names), samples_per_class, plt_idx)\n",
    "            plt.imshow(images[idx])\n",
    "            plt.title(class_name)\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    " show_sample_images(Images, labels, class_names)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrxdFzNigaYG"
   },
   "source": [
    "#### **2.2.3** <font color=red> [3 marks] </font><br>\n",
    "Based on the smallest and largest image dimensions, resize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyVvjNXqgIGe"
   },
   "outputs": [],
   "source": [
    "# Find the smallest and largest image dimensions from the data set\n",
    "\n",
    "def find_image_dimensions_extremes(images):\n",
    "    min_width = float('inf')\n",
    "    min_height = float('inf')\n",
    "    min_width = 0\n",
    "    min_height = 0\n",
    "\n",
    "    for imag in images:\n",
    "        heights, width = img.shape[:2]\n",
    "        if width < min_width:\n",
    "            min_width = width\n",
    "        if height < min_height:\n",
    "            min_height = height\n",
    "        if width > max_width:\n",
    "            max_width = width\n",
    "        if height > max_height:\n",
    "            max_height = height\n",
    "print(f\"Smallest dimensions: {min_widht}x{min_height}\")   \n",
    "print(f\"Largest dimensions: {max_width}x{max_height}\")\n",
    "find_image_dimensions_extremes(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fz7EutUrgKFZ"
   },
   "outputs": [],
   "source": [
    "# Resize the image dimensions\n",
    "\n",
    "def resize_image(image, target_size=(224, 224)):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        resized_image = cv2.resize(img, target_size)\n",
    "        resized_images.append(resized_image)\n",
    "    return np.array(resized_images)\n",
    "resized_images = resize_image(images, target_size=(224, 224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCB8uOckR5li"
   },
   "source": [
    "### **2.3 Encoding the classes** <font color=red> [3 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdC4dpTWt9eo"
   },
   "source": [
    "There are seven classes present in the data.\n",
    "\n",
    "We have extracted the images and their labels, and visualised their distribution. Now, we need to perform encoding on the labels. Encode the labels suitably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Nwd0Ztvkf7K"
   },
   "source": [
    "####**2.3.1** <font color=red> [3 marks] </font><br>\n",
    "Encode the target class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkyXDQN-660s"
   },
   "outputs": [],
   "source": [
    "# Encode the labels suitably\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_labels = label_encoder.fit_transform(labels)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_labels = to_categorical(integer_encoded_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNBM4hsuSaoj"
   },
   "source": [
    "### **2.4 Data Splitting** <font color=red> [5 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0xw-Qlh29cZ"
   },
   "source": [
    "#### **2.4.1** <font color=red> [5 marks] </font><br>\n",
    "Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TErpx_JOkwjO"
   },
   "outputs": [],
   "source": [
    "# Assign specified parts of the dataset to train and validation sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume: `images` is your resized image array, and `one_hot_labels` is the one-hot encoded label array\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, \n",
    "    one_hot_labels, \n",
    "    test_size=0.2,  # 20% for validation\n",
    "    random_state=42, \n",
    "    stratify=one_hot_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mILXPeY-X-zP"
   },
   "source": [
    "## **3. Model Building and Evaluation** <font color=red> [20 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4E0afHwy5M_i"
   },
   "source": [
    "### **3.1 Model building and training** <font color=red> [15 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsu8K3tL5a5Q"
   },
   "source": [
    "#### **3.1.1** <font color=red> [10 marks] </font><br>\n",
    "Build and compile the model. Use 3 convolutional layers. Add suitable normalisation, dropout, and fully connected layers to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awW9V2lmMK_d"
   },
   "source": [
    "Test out different configurations and report the results in conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oD7-2EXdz_Cl"
   },
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Define input shape (replace with your resized image dimensions, e.g., 128x128x3)\n",
    "input_shape = (128, 128, 3)\n",
    "num_classes = y_train.shape[1]  # e.g., 3 for 3 classes\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7t4duT1wX5wS"
   },
   "source": [
    "#### **3.1.2** <font color=red> [5 marks] </font><br>\n",
    "Train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcrEzo51Qj6w"
   },
   "source": [
    "Use appropriate metrics and callbacks as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7Ut0BicH_I8"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# Set training parameters\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWT-bIj9YVzh"
   },
   "source": [
    "### **3.2 Model Testing and Evaluation** <font color=red> [5 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjhU3i5v59d6"
   },
   "source": [
    "#### **3.2.1** <font color=red> [5 marks] </font><br>\n",
    "Evaluate the model on test dataset. Derive appropriate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_MtfUM_4y7j"
   },
   "outputs": [],
   "source": [
    "# Evaluate on the test set; display suitable metrics\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the labels\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = y_pred_probs.argmax(axis=1)\n",
    "y_true = y_test.argmax(axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utro5JdHS0JM"
   },
   "source": [
    "## **4. Data Augmentation** <font color=red> [optional] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T6QlG4eS4xi"
   },
   "source": [
    "#### **4.1 Create a Data Augmentation Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AXlfuoa4jQV"
   },
   "source": [
    "##### **4.1.1**\n",
    "Define augmentation steps for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbHCwkX0dq0R"
   },
   "outputs": [],
   "source": [
    "# Define augmentation steps to augment images\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define augmentation strategy\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# For validation/testing, usually only rescaling is applied\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07i11vgMEmM2"
   },
   "source": [
    "Augment and resample the images.\n",
    "In case of class imbalance, you can also perform adequate undersampling on the majority class and augment those images to ensure consistency in the input datasets for both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chvmgE2r4xPZ"
   },
   "source": [
    "Augment the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-JBheeYFS8d"
   },
   "outputs": [],
   "source": [
    "# Create a function to augment the images\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_augmentation_model():\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomTranslation(0.1, 0.1),\n",
    "        layers.RandomContrast(0.1)\n",
    "    ])\n",
    "    return data_augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ddy1y1nPIlvM"
   },
   "outputs": [],
   "source": [
    "# Create the augmented training dataset\n",
    "\n",
    "# First, get the augmentation model\n",
    "augmenter = get_augmentation_model()\n",
    "\n",
    "# Define a function to apply augmentation to images and keep labels unchanged\n",
    "def augment_data(image, label):\n",
    "    return augmenter(image), label\n",
    "\n",
    "# Apply the augmentation function to your training dataset\n",
    "augmented_train_ds = train_ds.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Optional: Prefetch for performance\n",
    "augmented_train_ds = augmented_train_ds.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZYekkw9TCvP"
   },
   "source": [
    "##### **4.1.2**\n",
    "\n",
    "Train the model on the new augmented dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBcRbt57FEct"
   },
   "outputs": [],
   "source": [
    "# Train the model using augmented images\n",
    "\n",
    "# Train the model using the augmented training dataset\n",
    "history_aug = model.fit(\n",
    "    augmented_train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFPuXAvHkJVz"
   },
   "source": [
    "## **5. Conclusions** <font color = red> [5 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33tWCHjpO5hH"
   },
   "source": [
    "#### **5.1 Conclude with outcomes and insights gained** <font color =red> [5 marks] </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3e1TLo2kWi0"
   },
   "source": [
    "* Report your findings about the data\n",
    "* Report model training results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1KW2JSuqBLb3DdmqZSAHtN2K0gX8C2HcV",
     "timestamp": 1740722968634
    },
    {
     "file_id": "1XXsgvgvRpr1OqI_K70kBWgfsI9bByK3r",
     "timestamp": 1738303842187
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
